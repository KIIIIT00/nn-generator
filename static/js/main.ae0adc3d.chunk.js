(window.webpackJsonp=window.webpackJsonp||[]).push([[0],{13:function(e,t,a){},14:function(e,t,a){},15:function(e,t,a){"use strict";a.r(t);var n=a(0),r=a.n(n),s=a(3),l=a.n(s);a(13),a(14);var o=()=>{const[e,t]=Object(n.useState)([{neurons:64,activation:"relu"},{neurons:32,activation:"relu"},{neurons:1,activation:"sigmoid"}]),[a,s]=Object(n.useState)("adam"),[l,o]=Object(n.useState)("bce"),[i,c]=Object(n.useState)(10),[m,d]=Object(n.useState)(32),[u,p]=Object(n.useState)(.001),[b,g]=Object(n.useState)("custom"),[f,h]=Object(n.useState)(!0),[_,v]=Object(n.useState)(""),[E,N]=Object(n.useState)(10),x=["relu","sigmoid","tanh","softmax","leaky_relu","elu","selu","gelu","prelu","none"],w=(a,n,r)=>{const s=[...e];s[a]={...s[a],[n]:r},t(s)},y=()=>{let t="import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\n";"custom"!==b?(t+="\n# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u8aad\u307f\u8fbc\u307f\nimport torchvision\nimport torchvision.transforms as transforms\n","mnist"===b?t+=`\n# MNIST\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u8aad\u307f\u8fbc\u307f\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n\n# \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u306e\u4f5c\u6210\ntrain_loader = DataLoader(train_dataset, batch_size=${m}, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=${m}, shuffle=False)\n\n# \u5165\u529b\u5f62\u72b6\u306e\u8a2d\u5b9a\ninput_size = 784  # 28x28\n`:"fashion_mnist"===b?t+=`\n# Fashion MNIST\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u8aad\u307f\u8fbc\u307f\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.2860,), (0.3530,))\n])\n\ntrain_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\ntest_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n\n# \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u306e\u4f5c\u6210\ntrain_loader = DataLoader(train_dataset, batch_size=${m}, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=${m}, shuffle=False)\n\n# \u5165\u529b\u5f62\u72b6\u306e\u8a2d\u5b9a\ninput_size = 784  # 28x28\n`:"cifar10"===b&&(t+=`\n# CIFAR-10\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u8aad\u307f\u8fbc\u307f\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n])\n\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n\n# \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u306e\u4f5c\u6210\ntrain_loader = DataLoader(train_dataset, batch_size=${m}, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=${m}, shuffle=False)\n\n# \u5165\u529b\u5f62\u72b6\u306e\u8a2d\u5b9a\ninput_size = 3 * 32 * 32  # 3x32x32\n`)):t+=`\n# \u30ab\u30b9\u30bf\u30e0\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\n# \u3053\u3053\u306b\u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\u3068\u524d\u51e6\u7406\u30b3\u30fc\u30c9\u3092\u8ffd\u52a0\nX = torch.randn(1200, ${E})\ny = torch.randint(0, 2, (1200, 1)).float()\n\n# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8a13\u7df4\u7528\u3068\u691c\u8a3c\u7528\u306b\u5206\u5272\ndataset = TensorDataset(X, y)\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\n# \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u306e\u4f5c\u6210\ntrain_loader = DataLoader(train_dataset, batch_size=${m}, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=${m}, shuffle=False)\n\n# \u5165\u529b\u5f62\u72b6\u306e\u8a2d\u5b9a\ninput_size = ${E}\n`,t+="\n# \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.layers = nn.Sequential(\n";let n="mnist"===b||"fashion_mnist"===b?784:"cifar10"===b?3072:E;e.forEach((e,a)=>{let r="";"relu"===e.activation?r="nn.ReLU()":"sigmoid"===e.activation?r="nn.Sigmoid()":"tanh"===e.activation?r="nn.Tanh()":"softmax"===e.activation?r="nn.Softmax(dim=1)":"leaky_relu"===e.activation?r="nn.LeakyReLU(0.1)":"elu"===e.activation?r="nn.ELU()":"selu"===e.activation?r="nn.SELU()":"gelu"===e.activation?r="nn.GELU()":"prelu"===e.activation?r="nn.PReLU()":"none"===e.activation&&(r=""),t+=`            nn.Linear(${n}, ${e.neurons}),\n`,r&&(t+=`            ${r},\n`),n=e.neurons}),t=t.slice(0,-2),t+='\n        )\n    \n    def forward(self, x):\n        if x.dim() > 2:\n            x = x.view(x.size(0), -1)  # \u30d5\u30e9\u30c3\u30c8\u5316\n        return self.layers(x)\n\n# \u30e2\u30c7\u30eb\u3068\u30c7\u30d0\u30a4\u30b9\u306e\u8a2d\u5b9a\ndevice = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")\nmodel = NeuralNetwork().to(device)\nprint(model)\n\n# \u640d\u5931\u95a2\u6570\u3068\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc\u306e\u8a2d\u5b9a\n',"bce"===l?t+="criterion = nn.BCELoss()\n":"bce_with_logits"===l?t+="criterion = nn.BCEWithLogitsLoss()\n":"cross_entropy"===l?t+="criterion = nn.CrossEntropyLoss()\n":"nll"===l?t+="criterion = nn.NLLLoss()\n":"mse"===l?t+="criterion = nn.MSELoss()\n":"l1"===l?t+="criterion = nn.L1Loss()\n":"smooth_l1"===l?t+="criterion = nn.SmoothL1Loss()\n":"huber"===l&&(t+="criterion = nn.HuberLoss()\n"),"adam"===a?t+=`optimizer = optim.Adam(model.parameters(), lr=${u})\n`:"sgd"===a?t+=`optimizer = optim.SGD(model.parameters(), lr=${u}, momentum=0.9)\n`:"rmsprop"===a?t+=`optimizer = optim.RMSprop(model.parameters(), lr=${u})\n`:"adagrad"===a?t+=`optimizer = optim.Adagrad(model.parameters(), lr=${u})\n`:"adadelta"===a?t+=`optimizer = optim.Adadelta(model.parameters(), lr=${u})\n`:"adamw"===a&&(t+=`optimizer = optim.AdamW(model.parameters(), lr=${u})\n`),t+=`\n# \u8a13\u7df4\u95a2\u6570\ndef train(model, train_loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for inputs, targets in train_loader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        # \u52fe\u914d\u3092\u30bc\u30ed\u306b\u30ea\u30bb\u30c3\u30c8\n        optimizer.zero_grad()\n        \n        # \u9806\u4f1d\u64ad + \u9006\u4f1d\u64ad + \u6700\u9069\u5316\n        outputs = model(inputs)\n        \n        # \u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5f62\u72b6\u3092\u8abf\u6574\uff08\u5fc5\u8981\u306a\u5834\u5408\uff09\n        if outputs.shape != targets.shape:\n            if outputs.shape[1] == 1:\n                # \u30d0\u30a4\u30ca\u30ea\u5206\u985e\u306e\u5834\u5408\n                targets = targets.float().view(-1, 1)\n            else:\n                # \u591a\u30af\u30e9\u30b9\u5206\u985e\u306e\u5834\u5408\u3001\u30e9\u30d9\u30eb\u3068\u3057\u3066\u306e\u5f62\u72b6\u306b\u5909\u63db\n                targets = targets.long().view(-1)\n        \n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        \n        # \u7cbe\u5ea6\u306e\u8a08\u7b97\uff08\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u307e\u305f\u306f\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u306b\u5bfe\u5fdc\uff09\n        if outputs.shape[1] == 1:  # \u30d0\u30a4\u30ca\u30ea\u5206\u985e\n            predicted = (outputs > 0.5).float()\n            total += targets.size(0)\n            correct += (predicted == targets).sum().item()\n        else:  # \u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n    \n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc = 100. * correct / total\n    return epoch_loss, epoch_acc\n\n# \u8a55\u4fa1\u95a2\u6570\ndef evaluate(model, test_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            outputs = model(inputs)\n            \n            # \u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5f62\u72b6\u3092\u8abf\u6574\uff08\u5fc5\u8981\u306a\u5834\u5408\uff09\n            if outputs.shape != targets.shape:\n                if outputs.shape[1] == 1:\n                    # \u30d0\u30a4\u30ca\u30ea\u5206\u985e\u306e\u5834\u5408\n                    targets = targets.float().view(-1, 1)\n                else:\n                    # \u591a\u30af\u30e9\u30b9\u5206\u985e\u306e\u5834\u5408\u3001\u30e9\u30d9\u30eb\u3068\u3057\u3066\u306e\u5f62\u72b6\u306b\u5909\u63db\n                    targets = targets.long().view(-1)\n            \n            loss = criterion(outputs, targets)\n            running_loss += loss.item()\n            \n            # \u7cbe\u5ea6\u306e\u8a08\u7b97\uff08\u30d0\u30a4\u30ca\u30ea\u5206\u985e\u307e\u305f\u306f\u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\u306b\u5bfe\u5fdc\uff09\n            if outputs.shape[1] == 1:  # \u30d0\u30a4\u30ca\u30ea\u5206\u985e\n                predicted = (outputs > 0.5).float()\n                total += targets.size(0)\n                correct += (predicted == targets).sum().item()\n            else:  # \u30de\u30eb\u30c1\u30af\u30e9\u30b9\u5206\u985e\n                _, predicted = outputs.max(1)\n                total += targets.size(0)\n                correct += predicted.eq(targets).sum().item()\n    \n    epoch_loss = running_loss / len(test_loader)\n    epoch_acc = 100. * correct / total\n    return epoch_loss, epoch_acc\n\n# \u8a13\u7df4\u30eb\u30fc\u30d7\ntrain_losses = []\ntrain_accs = []\nval_losses = []\nval_accs = []\n\nfor epoch in range(${i}):\n    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n    val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n    \n    train_losses.append(train_loss)\n    train_accs.append(train_acc)\n    val_losses.append(val_loss)\n    val_accs.append(val_acc)\n    \n    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n\nprint('\u8a13\u7df4\u5b8c\u4e86')\n`,f&&(t+="\n# \u8a13\u7df4\u904e\u7a0b\u306e\u53ef\u8996\u5316\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(train_accs)\nplt.plot(val_accs)\nplt.title('\u30e2\u30c7\u30eb\u7cbe\u5ea6')\nplt.ylabel('\u7cbe\u5ea6 (%)')\nplt.xlabel('\u30a8\u30dd\u30c3\u30af')\nplt.legend(['\u8a13\u7df4', '\u691c\u8a3c'], loc='lower right')\n\nplt.subplot(1, 2, 2)\nplt.plot(train_losses)\nplt.plot(val_losses)\nplt.title('\u30e2\u30c7\u30eb\u640d\u5931')\nplt.ylabel('\u640d\u5931')\nplt.xlabel('\u30a8\u30dd\u30c3\u30af')\nplt.legend(['\u8a13\u7df4', '\u691c\u8a3c'], loc='upper right')\n\nplt.tight_layout()\nplt.show()\n");const r=(e=>{const t=e.split("\n");let a=1/0;return t.forEach(e=>{if(""!==e.trim()){const t=e.match(/^\s*/);t&&t[0].length<a&&(a=t[0].length)}}),a===1/0&&(a=0),t.map(e=>""===e.trim()?"":e.substring(a)).join("\n")})(t+="\n# \u30e2\u30c7\u30eb\u306e\u4fdd\u5b58\ntorch.save(model.state_dict(), 'model.pth')\nprint(\"\u30e2\u30c7\u30eb\u3092\u4fdd\u5b58\u3057\u307e\u3057\u305f\u3002\")\n");v(r)};return Object(n.useEffect)(()=>{y()},[]),r.a.createElement("div",{className:"flex flex-col p-4 max-w-4xl mx-auto"},r.a.createElement("h1",{className:"text-2xl font-bold mb-6 text-center"},"\u30ce\u30fc\u30b3\u30fc\u30c9 \u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af \u30b3\u30fc\u30c9\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u30fc"),r.a.createElement("div",{className:"grid grid-cols-1 md:grid-cols-3 gap-4 mb-4"},r.a.createElement("div",{className:"bg-gray-100 p-4 rounded-lg"},r.a.createElement("h2",{className:"text-lg font-semibold mb-2"},"\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u8a2d\u5b9a"),r.a.createElement("div",{className:"mb-2"},r.a.createElement("label",{className:"block text-sm mb-1"},"\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8:"),r.a.createElement("select",{className:"w-full p-2 border rounded",value:b,onChange:e=>g(e.target.value)},["mnist","fashion_mnist","cifar10","custom"].map(e=>r.a.createElement("option",{key:e,value:e},e)))),"custom"===b&&r.a.createElement("div",{className:"mb-2"},r.a.createElement("label",{className:"block text-sm mb-1"},"\u5165\u529b\u5f62\u72b6 (\u7279\u5fb4\u91cf\u306e\u6570):"),r.a.createElement("input",{type:"number",className:"w-full p-2 border rounded",value:E,onChange:e=>N(parseInt(e.target.value)),min:"1"}))),r.a.createElement("div",{className:"bg-gray-100 p-4 rounded-lg"},r.a.createElement("h2",{className:"text-lg font-semibold mb-2"},"\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u8a2d\u5b9a"),r.a.createElement("div",{className:"mb-2"},r.a.createElement("label",{className:"block text-sm mb-1"},"\u30aa\u30d7\u30c6\u30a3\u30de\u30a4\u30b6\u30fc:"),r.a.createElement("select",{className:"w-full p-2 border rounded",value:a,onChange:e=>s(e.target.value)},["adam","sgd","rmsprop","adagrad","adadelta","adamw"].map(e=>r.a.createElement("option",{key:e,value:e},e)))),r.a.createElement("div",{className:"mb-2"},r.a.createElement("label",{className:"block text-sm mb-1"},"\u5b66\u7fd2\u7387:"),r.a.createElement("input",{type:"number",className:"w-full p-2 border rounded",value:u,onChange:e=>p(parseFloat(e.target.value)),min:"0.0001",max:"1",step:"0.0001"})),r.a.createElement("div",{className:"mb-2"},r.a.createElement("label",{className:"block text-sm mb-1"},"\u640d\u5931\u95a2\u6570:"),r.a.createElement("select",{className:"w-full p-2 border rounded",value:l,onChange:e=>o(e.target.value)},["bce","bce_with_logits","cross_entropy","nll","mse","l1","smooth_l1","huber"].map(e=>r.a.createElement("option",{key:e,value:e},e)))),r.a.createElement("div",{className:"mb-2"},r.a.createElement("label",{className:"block text-sm mb-1"},"\u30a8\u30dd\u30c3\u30af\u6570:"),r.a.createElement("input",{type:"number",className:"w-full p-2 border rounded",value:i,onChange:e=>c(parseInt(e.target.value)),min:"1"})),r.a.createElement("div",{className:"mb-2"},r.a.createElement("label",{className:"block text-sm mb-1"},"\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba:"),r.a.createElement("input",{type:"number",className:"w-full p-2 border rounded",value:m,onChange:e=>d(parseInt(e.target.value)),min:"1"}))),r.a.createElement("div",{className:"bg-gray-100 p-4 rounded-lg"},r.a.createElement("h2",{className:"text-lg font-semibold mb-2"},"\u8ffd\u52a0\u8a2d\u5b9a"),r.a.createElement("div",{className:"mb-4"},r.a.createElement("label",{className:"flex items-center"},r.a.createElement("input",{type:"checkbox",checked:f,onChange:e=>h(e.target.checked),className:"mr-2"}),r.a.createElement("span",null,"\u8a13\u7df4\u904e\u7a0b\u306e\u53ef\u8996\u5316\u3092\u542b\u3081\u308b"))))),r.a.createElement("div",{className:"bg-gray-100 p-4 rounded-lg mb-4"},r.a.createElement("div",{className:"flex justify-between items-center mb-2"},r.a.createElement("h2",{className:"text-lg font-semibold"},"\u30ec\u30a4\u30e4\u30fc\u8a2d\u5b9a"),r.a.createElement("button",{onClick:()=>{t([...e,{neurons:32,activation:"relu"}])},className:"bg-blue-500 text-white px-3 py-1 rounded hover:bg-blue-600"},"\u30ec\u30a4\u30e4\u30fc\u3092\u8ffd\u52a0")),e.map((a,n)=>r.a.createElement("div",{key:n,className:"flex flex-wrap items-center mb-2 p-2 border rounded bg-white"},r.a.createElement("div",{className:"mr-2 mb-2 md:mb-0"},r.a.createElement("span",{className:"font-medium"},"\u30ec\u30a4\u30e4\u30fc ",n+1,":")),r.a.createElement("div",{className:"mr-2 mb-2 md:mb-0"},r.a.createElement("label",{className:"text-sm mr-1"},"\u30cb\u30e5\u30fc\u30ed\u30f3\u6570:"),r.a.createElement("input",{type:"number",className:"w-20 p-1 border rounded",value:a.neurons,onChange:e=>w(n,"neurons",parseInt(e.target.value)),min:"1"})),r.a.createElement("div",{className:"mr-2 mb-2 md:mb-0"},r.a.createElement("label",{className:"text-sm mr-1"},"\u6d3b\u6027\u5316\u95a2\u6570:"),r.a.createElement("select",{className:"p-1 border rounded",value:a.activation,onChange:e=>w(n,"activation",e.target.value)},x.map(e=>r.a.createElement("option",{key:e,value:e},e)))),r.a.createElement("div",{className:"ml-auto"},e.length>1&&r.a.createElement("button",{onClick:()=>(a=>{if(e.length>1){const n=[...e];n.splice(a,1),t(n)}})(n),className:"bg-red-500 text-white px-2 py-1 rounded hover:bg-red-600 text-sm"},"\u524a\u9664"))))),r.a.createElement("div",{className:"mb-4"},r.a.createElement("button",{onClick:y,className:"bg-green-600 text-white px-4 py-2 rounded hover:bg-green-700 w-full font-bold"},"Python\u30b3\u30fc\u30c9\u3092\u751f\u6210")),r.a.createElement("div",{className:"bg-gray-900 text-gray-100 p-4 rounded-lg overflow-auto"},r.a.createElement("div",{className:"flex justify-between items-center mb-2"},r.a.createElement("h2",{className:"text-lg font-semibold"},"\u751f\u6210\u3055\u308c\u305f\u30b3\u30fc\u30c9"),r.a.createElement("div",{className:"flex"},r.a.createElement("button",{onClick:()=>{navigator.clipboard.writeText(_).then(()=>{alert("\u30b3\u30fc\u30c9\u304c\u30af\u30ea\u30c3\u30d7\u30dc\u30fc\u30c9\u306b\u30b3\u30d4\u30fc\u3055\u308c\u307e\u3057\u305f\uff01")}).catch(e=>{console.error("\u30b3\u30d4\u30fc\u306b\u5931\u6557\u3057\u307e\u3057\u305f:",e),alert("\u30b3\u30d4\u30fc\u306b\u5931\u6557\u3057\u307e\u3057\u305f\u3002\u624b\u52d5\u3067\u30b3\u30d4\u30fc\u3057\u3066\u304f\u3060\u3055\u3044\u3002")})},className:"bg-blue-500 text-white px-3 py-1 rounded hover:bg-blue-600 mr-2"},"\u30b3\u30d4\u30fc"),r.a.createElement("button",{onClick:()=>{const e=document.createElement("a"),t=new Blob([_],{type:"text/plain"});e.href=URL.createObjectURL(t),e.download="neural_network.py",document.body.appendChild(e),e.click(),document.body.removeChild(e)},className:"bg-green-500 text-white px-3 py-1 rounded hover:bg-green-600"},"\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9"))),r.a.createElement("pre",{className:"whitespace-pre text-left overflow-x-auto"},r.a.createElement("code",null,_))))};var i=function(){return r.a.createElement("div",{className:"App"},r.a.createElement(o,null))};var c=e=>{e&&e instanceof Function&&a.e(3).then(a.bind(null,16)).then(t=>{let{getCLS:a,getFID:n,getFCP:r,getLCP:s,getTTFB:l}=t;a(e),n(e),r(e),s(e),l(e)})};l.a.createRoot(document.getElementById("root")).render(r.a.createElement(r.a.StrictMode,null,r.a.createElement(i,null))),c()},4:function(e,t,a){e.exports=a(15)}},[[4,1,2]]]);
//# sourceMappingURL=main.ae0adc3d.chunk.js.map